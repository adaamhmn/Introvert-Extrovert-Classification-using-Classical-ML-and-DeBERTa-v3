{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13827078,"sourceType":"datasetVersion","datasetId":8796111},{"sourceId":4381,"sourceType":"datasetVersion","datasetId":2637}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nkaggle_data_DL = pd.read_csv('/kaggle/input/mbti-type/mbti_1.csv')\n\nkaggle_data_DL.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:16:50.653591Z","iopub.execute_input":"2025-11-22T15:16:50.654173Z","iopub.status.idle":"2025-11-22T15:16:51.940480Z","shell.execute_reply.started":"2025-11-22T15:16:50.654146Z","shell.execute_reply":"2025-11-22T15:16:51.939713Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"   type                                              posts\n0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n1  ENTP  'I'm finding the lack of me in these posts ver...\n2  INTP  'Good one  _____   https://www.youtube.com/wat...\n3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n4  ENTJ  'You're fired.|||That's another silly misconce...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>'I'm finding the lack of me in these posts ver...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>'You're fired.|||That's another silly misconce...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# Replace the '|||' separator with a space\nkaggle_data_DL['posts'] = kaggle_data_DL['posts'].str.replace('|||', ' ', regex=False)\n\n# Verify (no.4 specifically)\nprint(kaggle_data_DL['posts'].head(6))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:26:22.475686Z","iopub.execute_input":"2025-11-22T13:26:22.476176Z","iopub.status.idle":"2025-11-22T13:26:22.553584Z","shell.execute_reply.started":"2025-11-22T13:26:22.476150Z","shell.execute_reply":"2025-11-22T13:26:22.552956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove URLs\nimport re\n\ndef remove_urls(text):\n    return re.sub(r'http\\S+', '', text)\n\nkaggle_data_DL['posts'] = kaggle_data_DL['posts'].apply(remove_urls)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:26:25.271012Z","iopub.execute_input":"2025-11-22T13:26:25.271281Z","iopub.status.idle":"2025-11-22T13:26:25.405637Z","shell.execute_reply.started":"2025-11-22T13:26:25.271262Z","shell.execute_reply":"2025-11-22T13:26:25.404877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\nmbti_types = [\n    'infj', 'entp', 'intp', 'intj', 'entj', 'enfj', 'infp', 'enfp',\n    'isfp', 'istp', 'isfj', 'istj', 'estp', 'esfp', 'estj', 'esfj',\n    'introvert', 'extrovert'  \n]\n\ndef remove_leakage_words(text):\n    pattern = r'\\b(?:' + '|'.join(mbti_types) + r')\\b'\n    return re.sub(pattern, '', text, flags=re.IGNORECASE)  # ← key change\n\nkaggle_data_DL['posts'] = kaggle_data_DL['posts'].apply(remove_leakage_words)\nprint(kaggle_data_DL['posts'].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:26:27.084631Z","iopub.execute_input":"2025-11-22T13:26:27.084913Z","iopub.status.idle":"2025-11-22T13:26:36.621869Z","shell.execute_reply.started":"2025-11-22T13:26:27.084883Z","shell.execute_reply":"2025-11-22T13:26:36.621251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# normalize whitespace for a single text\n\nimport re\n\ndef normalize_whitespace(text):\n    return re.sub(r\"\\s+\", \" \", text).strip()\n\nkaggle_data_DL['posts'] = kaggle_data_DL['posts'].apply(normalize_whitespace)\nprint(kaggle_data_DL['posts'].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:26:58.173409Z","iopub.execute_input":"2025-11-22T13:26:58.173964Z","iopub.status.idle":"2025-11-22T13:27:01.180956Z","shell.execute_reply.started":"2025-11-22T13:26:58.173941Z","shell.execute_reply":"2025-11-22T13:27:01.180297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save CSV \nkaggle_data.to_csv('mbti_deeplearning_new.csv', index=False)\n\nprint(\"File saved successfully as 'mbti_deeplearning_new.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T13:28:00.855070Z","iopub.execute_input":"2025-11-22T13:28:00.855791Z","iopub.status.idle":"2025-11-22T13:28:02.505841Z","shell.execute_reply.started":"2025-11-22T13:28:00.855765Z","shell.execute_reply":"2025-11-22T13:28:02.505226Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Deberta**","metadata":{}},{"cell_type":"code","source":"# !pip install --upgrade protobuf==4.25.3\n# !pip install --upgrade transformers datasets sentencepiece\n# !pip install evaluate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding,\n)\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using Device: {device}\")\n\ndf = pd.read_csv(\"/kaggle/working/mbti_deeplearning_new.csv\")\n\n# Encode Labels\nle = LabelEncoder()\ndf[\"label\"] = le.fit_transform(df[\"type\"])\nprint(f\"Classes: {le.classes_}\")\nprint(\"Original Class Distribution:\\n\", df[\"label\"].value_counts())\n\n# Split 80/20\ntrain_df, val_df = train_test_split(\n    df, test_size=0.2, random_state=SEED, stratify=df[\"label\"]\n)\n\ntrain_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\nval_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:17:12.892520Z","iopub.execute_input":"2025-11-22T15:17:12.893125Z","iopub.status.idle":"2025-11-22T15:17:26.179369Z","shell.execute_reply.started":"2025-11-22T15:17:12.893098Z","shell.execute_reply":"2025-11-22T15:17:26.178538Z"}},"outputs":[{"name":"stderr","text":"2025-11-22 15:17:19.079315: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763824639.101893    8256 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763824639.108709    8256 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using Device: cuda\nClasses: ['Extrovert' 'Introvert']\nOriginal Class Distribution:\n label\n1    6676\n0    1999\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"model_name = \"microsoft/deberta-v3-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(batch):\n    return tokenizer(\n        batch[\"posts\"],\n        truncation=True,\n        max_length=512,\n        padding=False  \n    )\n\nprint(\"Tokenizing...\")\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\nval_dataset = val_dataset.map(tokenize_function, batched=True)\n\ntrain_dataset = train_dataset.rename_column(\"label\", \"labels\")\nval_dataset = val_dataset.rename_column(\"label\", \"labels\")\n\ncolumns_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\ntrain_dataset.set_format(type=\"torch\", columns=columns_to_keep)\nval_dataset.set_format(type=\"torch\", columns=columns_to_keep)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:17:26.180646Z","iopub.execute_input":"2025-11-22T15:17:26.180874Z","iopub.status.idle":"2025-11-22T15:17:45.058684Z","shell.execute_reply.started":"2025-11-22T15:17:26.180857Z","shell.execute_reply":"2025-11-22T15:17:45.057894Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Tokenizing...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6940 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb1999b4b2d947039a6c58c93b37c795"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1735 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be15e2ad578146d387b1a2c0440a16ce"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# weighted sampler\ntrain_labels = train_df[\"label\"].values\nclass_counts = np.bincount(train_labels)\nclass_weights = 1. / class_counts\nsample_weights = class_weights[train_labels]\n\nsampler = WeightedRandomSampler(\n    weights=sample_weights,\n    num_samples=len(sample_weights),\n    replacement=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:17:45.059455Z","iopub.execute_input":"2025-11-22T15:17:45.059705Z","iopub.status.idle":"2025-11-22T15:17:45.064758Z","shell.execute_reply.started":"2025-11-22T15:17:45.059678Z","shell.execute_reply":"2025-11-22T15:17:45.064011Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=2\n).to(device)\n\n\nclass CustomTrainer(Trainer):\n    def get_train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.args.train_batch_size,\n            sampler=sampler,  \n            collate_fn=self.data_collator,\n            num_workers=0     \n        )\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    \n    acc = accuracy_score(labels, predictions)\n    f1 = f1_score(labels, predictions, average=\"macro\")\n    \n    return {\"accuracy\": acc, \"f1_macro\": f1}\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1_macro\", \n    save_total_limit=1,\n    report_to=\"none\",\n    fp16=torch.cuda.is_available()\n)\n\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\nprint(\"Starting Training...\")\ntrainer.train()\n\ntrainer.save_model(\"/kaggle/working/debertav3\")\ntokenizer.save_pretrained(\"/kaggle/working/debertav3\")\n\ndef predict_personality(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n    \n    model.eval()\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n    pred_idx = torch.argmax(probs, dim=-1).item()\n    \n    label = le.inverse_transform([pred_idx])[0]\n    confidence = probs[0][pred_idx].item()\n    \n    return f\"{label} (Confidence: {confidence:.2%})\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:17:45.066230Z","iopub.execute_input":"2025-11-22T15:17:45.066667Z","iopub.status.idle":"2025-11-22T15:49:02.749215Z","shell.execute_reply.started":"2025-11-22T15:17:45.066645Z","shell.execute_reply":"2025-11-22T15:49:02.748313Z"}},"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_8256/3569527633.py:46: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n  trainer = CustomTrainer(\nThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n","output_type":"stream"},{"name":"stdout","text":"Starting Training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1302' max='1302' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1302/1302 31:11, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.464375</td>\n      <td>0.808646</td>\n      <td>0.746124</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.532700</td>\n      <td>0.420043</td>\n      <td>0.854179</td>\n      <td>0.790604</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.329900</td>\n      <td>0.524779</td>\n      <td>0.841499</td>\n      <td>0.782074</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport numpy as np\n\n# Run prediction on validation set\npred_output = trainer.predict(val_dataset)\n\n# Extract logits and true labels\nlogits = pred_output.predictions\ny_true = pred_output.label_ids\n\n# Convert logits → predicted class indices\ny_pred = np.argmax(logits, axis=-1)\n\nprecision = precision_score(y_true, y_pred, average=\"macro\")\nrecall = recall_score(y_true, y_pred, average=\"macro\")\nf1 = f1_score(y_true, y_pred, average=\"macro\")\n\nprint(f\"Precision (macro): {precision:.4f}\")\nprint(f\"Recall (macro):    {recall:.4f}\")\nprint(f\"F1 Score (macro):  {f1:.4f}\")\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(\n    y_true, \n    y_pred, \n    target_names=le.classes_\n))\n\ncm = confusion_matrix(y_true, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:49:02.750248Z","iopub.execute_input":"2025-11-22T15:49:02.750583Z","iopub.status.idle":"2025-11-22T15:49:53.002406Z","shell.execute_reply.started":"2025-11-22T15:49:02.750552Z","shell.execute_reply":"2025-11-22T15:49:53.001771Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Precision (macro): 0.7964\nRecall (macro):    0.7853\nF1 Score (macro):  0.7906\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n   Extrovert       0.69      0.66      0.68       400\n   Introvert       0.90      0.91      0.91      1335\n\n    accuracy                           0.85      1735\n   macro avg       0.80      0.79      0.79      1735\nweighted avg       0.85      0.85      0.85      1735\n\nConfusion Matrix:\n [[ 263  137]\n [ 116 1219]]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def predict_personality(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n    \n    model.eval()\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n    pred_idx = torch.argmax(probs, dim=-1).item()\n    \n    label = le.inverse_transform([pred_idx])[0]\n    confidence = probs[0][pred_idx].item()\n    \n    return f\"{label} (Confidence: {confidence:.2%})\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T16:02:03.618750Z","iopub.execute_input":"2025-11-22T16:02:03.619057Z","iopub.status.idle":"2025-11-22T16:02:03.624056Z","shell.execute_reply.started":"2025-11-22T16:02:03.619038Z","shell.execute_reply":"2025-11-22T16:02:03.623486Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Textbook extrovert vs \"Reddit-style\" extrovert (casual, opinionated)\ntextbook_extrovert = \"I feel energized when i am around people.\"\nreddit_extrovert = \"Lmao that is hilarious! I literally shouted at my screen. We should totally do a meetup for this sub, it would be chaotic but fun.\"\n\nprint(f\"Textbook Extrovert: {predict_personality(textbook_extrovert)}\")\nprint(f\"Reddit Extrovert:   {predict_personality(reddit_extrovert)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T16:09:56.587484Z","iopub.execute_input":"2025-11-22T16:09:56.588400Z","iopub.status.idle":"2025-11-22T16:09:56.640447Z","shell.execute_reply.started":"2025-11-22T16:09:56.588337Z","shell.execute_reply":"2025-11-22T16:09:56.639847Z"}},"outputs":[{"name":"stdout","text":"Textbook Extrovert: Introvert (Confidence: 64.95%)\nReddit Extrovert:   Extrovert (Confidence: 62.23%)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# textbook introvert vs \"Reddit-style\" introvert (casual, opinionated)\ntextbook_introvert = \"I recharge my energy by spending time alone. Social interactions often feel draining to me, and I prefer deep, one-on-one conversations over large groups.\"\nreddit_introvert = \"Ugh, honestly I just want to stay in my room and play video games all weekend. People are so exhausting lol. Does anyone else feel like hiding when the doorbell rings?\"\n\nprint(f\"Textbook Introvert: {predict_personality(textbook_introvert)}\")\nprint(f\"Reddit Introvert:   {predict_personality(reddit_introvert)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T16:09:58.586559Z","iopub.execute_input":"2025-11-22T16:09:58.587409Z","iopub.status.idle":"2025-11-22T16:09:58.639853Z","shell.execute_reply.started":"2025-11-22T16:09:58.587381Z","shell.execute_reply":"2025-11-22T16:09:58.639305Z"}},"outputs":[{"name":"stdout","text":"Textbook Introvert: Introvert (Confidence: 69.10%)\nReddit Introvert:   Introvert (Confidence: 64.35%)\n","output_type":"stream"}],"execution_count":23}]}