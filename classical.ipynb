{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4381,"sourceType":"datasetVersion","datasetId":2637},{"sourceId":13827078,"sourceType":"datasetVersion","datasetId":8796111}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nkaggle_data = pd.read_csv('/kaggle/input/mbti-type/mbti_1.csv')\n\nkaggle_data.head()\n\nkaggle_data[\"type\"].value_counts()\nkaggle_data[\"posts\"].count()\nkaggle_data[\"type\"] = kaggle_data[\"type\"].str.upper().str[0].map({\n    \"I\": \"Introvert\",\n    \"E\": \"Extrovert\"\n})\nkaggle_data.head()\nkaggle_data[\"type\"].value_counts()\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\n# Separate posts\nintro_posts = \" \".join(kaggle_data[kaggle_data[\"type\"] == \"Introvert\"][\"posts\"].astype(str))\nextro_posts = \" \".join(kaggle_data[kaggle_data[\"type\"] == \"Extrovert\"][\"posts\"].astype(str))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:20:40.082728Z","iopub.execute_input":"2025-11-22T11:20:40.082988Z","iopub.status.idle":"2025-11-22T11:20:41.442950Z","shell.execute_reply.started":"2025-11-22T11:20:40.082943Z","shell.execute_reply":"2025-11-22T11:20:41.439408Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Replace '|||' separator with space\nkaggle_data['posts'] = kaggle_data['posts'].str.replace('|||', ' ', regex=False)\n\n# Verify (no.4 specifically)\nprint(kaggle_data['posts'].head(6))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:05:26.564763Z","iopub.execute_input":"2025-11-22T11:05:26.565063Z","iopub.status.idle":"2025-11-22T11:05:26.655502Z","shell.execute_reply.started":"2025-11-22T11:05:26.565036Z","shell.execute_reply":"2025-11-22T11:05:26.654913Z"}},"outputs":[{"name":"stdout","text":"0    'http://www.youtube.com/watch?v=qsXHcwe3krw ht...\n1    'I'm finding the lack of me in these posts ver...\n2    'Good one  _____   https://www.youtube.com/wat...\n3    'Dear INTP,   I enjoyed our conversation the o...\n4    'You're fired. That's another silly misconcept...\n5    '18/37 @.@ Science  is not perfect. No scienti...\nName: posts, dtype: object\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# lowercase\nkaggle_data['posts'] = kaggle_data['posts'].str.lower()\n\n# Verify\nprint(kaggle_data['posts'].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:05:26.656239Z","iopub.execute_input":"2025-11-22T11:05:26.656525Z","iopub.status.idle":"2025-11-22T11:05:26.805245Z","shell.execute_reply.started":"2025-11-22T11:05:26.656501Z","shell.execute_reply":"2025-11-22T11:05:26.804272Z"}},"outputs":[{"name":"stdout","text":"0    'http://www.youtube.com/watch?v=qsxhcwe3krw ht...\n1    'i'm finding the lack of me in these posts ver...\n2    'good one  _____   https://www.youtube.com/wat...\n3    'dear intp,   i enjoyed our conversation the o...\n4    'you're fired. that's another silly misconcept...\nName: posts, dtype: object\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Remove URLs\nimport re\n\ndef remove_urls(text):\n    return re.sub(r'http\\S+', '', text)\n\nkaggle_data['posts'] = kaggle_data['posts'].apply(remove_urls)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:05:26.807257Z","iopub.execute_input":"2025-11-22T11:05:26.807497Z","iopub.status.idle":"2025-11-22T11:05:26.927436Z","shell.execute_reply.started":"2025-11-22T11:05:26.807469Z","shell.execute_reply":"2025-11-22T11:05:26.926861Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Remove MBTI Keywords (Prevent data leakage)\n\nmbti_types = [\n    'infj', 'entp', 'intp', 'intj', 'entj', 'enfj', 'infp', 'enfp',\n    'isfp', 'istp', 'isfj', 'istj', 'estp', 'esfp', 'estj', 'esfj',\n    'introvert', 'extrovert'  \n]\n\ndef remove_leakage_words(text):\n    # join all types into one pattern: (infj|entp|intp|...)\n    pattern = r'\\b(?:' + '|'.join(mbti_types) + r')\\b'\n    return re.sub(pattern, '', text)\n\nkaggle_data['posts'] = kaggle_data['posts'].apply(remove_leakage_words)\n\n# verify\nprint(kaggle_data['posts'].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:05:26.928562Z","iopub.execute_input":"2025-11-22T11:05:26.928796Z","iopub.status.idle":"2025-11-22T11:05:28.911143Z","shell.execute_reply.started":"2025-11-22T11:05:26.928781Z","shell.execute_reply":"2025-11-22T11:05:28.910482Z"}},"outputs":[{"name":"stdout","text":"0    '   and  moments    sportscenter not top ten p...\n1    'i'm finding the lack of me in these posts ver...\n2    'good one  _____    of course, to which i say ...\n3    'dear ,   i enjoyed our conversation the other...\n4    'you're fired. that's another silly misconcept...\nName: posts, dtype: object\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Remove Punctuation & Numbers\nimport nltk\nfrom nltk.corpus import stopwords\n\ndef remove_noise(text):\n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    # Remove numbers\n    text = re.sub(r'\\d+', '', text)\n    return text\n\nkaggle_data['posts'] = kaggle_data['posts'].apply(remove_noise)\nprint(kaggle_data['posts'].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:05:28.911831Z","iopub.execute_input":"2025-11-22T11:05:28.912024Z","iopub.status.idle":"2025-11-22T11:05:31.522158Z","shell.execute_reply.started":"2025-11-22T11:05:28.912008Z","shell.execute_reply":"2025-11-22T11:05:31.521276Z"}},"outputs":[{"name":"stdout","text":"0       and  moments    sportscenter not top ten pl...\n1    im finding the lack of me in these posts very ...\n2    good one  _____    of course to which i say i ...\n3    dear    i enjoyed our conversation the other d...\n4    youre fired thats another silly misconception ...\nName: posts, dtype: object\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import emoji\n\n# Convert Emoji \ndef convert_emojis(text):\n    text = emoji.demojize(text)\n    text = text.replace(\":\", \"\").replace(\"_\", \" \")\n    return text\n\ndef emoji_process(text):\n    return convert_emojis(text)\n\nkaggle_data['posts'] = kaggle_data['posts'].apply(emoji_process)\n\n# verify\nprint(kaggle_data['posts'].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:05:31.523060Z","iopub.execute_input":"2025-11-22T11:05:31.523868Z","iopub.status.idle":"2025-11-22T11:06:11.222258Z","shell.execute_reply.started":"2025-11-22T11:05:31.523846Z","shell.execute_reply":"2025-11-22T11:06:11.221629Z"}},"outputs":[{"name":"stdout","text":"0       and  moments    sportscenter not top ten pl...\n1    im finding the lack of me in these posts very ...\n2    good one           of course to which i say i ...\n3    dear    i enjoyed our conversation the other d...\n4    youre fired thats another silly misconception ...\nName: posts, dtype: object\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Remove Stopwords\nstop_words = set(stopwords.words('english'))\n\ndef remove_stopwords(text):\n    # Split into words, check if stopword, join \n    return ' '.join([word for word in str(text).split() if word not in stop_words])\n    \nkaggle_data['posts'] = kaggle_data['posts'].apply(remove_stopwords)\n\n# Verify\nprint(kaggle_data['posts'].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:06:44.398627Z","iopub.execute_input":"2025-11-22T11:06:44.399284Z","iopub.status.idle":"2025-11-22T11:06:45.838507Z","shell.execute_reply.started":"2025-11-22T11:06:44.399261Z","shell.execute_reply":"2025-11-22T11:06:45.837754Z"}},"outputs":[{"name":"stdout","text":"0    moments sportscenter top ten plays pranks life...\n1    im finding lack posts alarming sex boring posi...\n2    good one course say know thats blessing curse ...\n3    dear enjoyed conversation day esoteric gabbing...\n4    youre fired thats another silly misconception ...\nName: posts, dtype: object\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Lemmatize\nimport nltk\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\n#  map NLTK tags\ndef get_wordnet_pos(treebank_tag):\n    if treebank_tag.startswith('J'):\n        return wordnet.ADJ\n    elif treebank_tag.startswith('V'):\n        return wordnet.VERB\n    elif treebank_tag.startswith('N'):\n        return wordnet.NOUN\n    elif treebank_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN # Default to Noun\n\ndef lemmatize_text_smart(text):\n    # split, tag , join\n    tokens = str(text).split()\n    pos_tags = nltk.pos_tag(tokens)\n    return \" \".join([lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags])\n\nprint(\"lemmatizing...\")\nkaggle_data['posts'] = kaggle_data['posts'].apply(lemmatize_text_smart)\nprint(\"Complete\")\n\n# verify\nprint(kaggle_data['posts'].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:07:39.730389Z","iopub.execute_input":"2025-11-22T11:07:39.730970Z","iopub.status.idle":"2025-11-22T11:11:34.652257Z","shell.execute_reply.started":"2025-11-22T11:07:39.730938Z","shell.execute_reply":"2025-11-22T11:11:34.651501Z"}},"outputs":[{"name":"stdout","text":"lemmatizing...\nComplete\n0    moment sportscenter top ten play prank lifecha...\n1    im find lack post alarm sex boring position of...\n2    good one course say know thats bless curse abs...\n3    dear enjoyed conversation day esoteric gabbing...\n4    youre fire thats another silly misconception a...\nName: posts, dtype: object\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Save CSV \nkaggle_data.to_csv('mbti_traditional_new.csv', index=False)\n\nprint(\"File saved successfully as 'mbti_traditional_new.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:12:31.571671Z","iopub.execute_input":"2025-11-22T11:12:31.571964Z","iopub.status.idle":"2025-11-22T11:12:32.497057Z","shell.execute_reply.started":"2025-11-22T11:12:31.571943Z","shell.execute_reply":"2025-11-22T11:12:32.496439Z"}},"outputs":[{"name":"stdout","text":"File saved successfully as 'mbti_traditional_new.csv'\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# nltk.download('punkt')\n# nltk.download('punkt_tab')\n# !pip uninstall -y scikit-learn sklearn imbalanced-learn\n# !pip install -U scikit-learn imbalanced-learn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom gensim.models import FastText\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer  \nfrom sklearn.decomposition import TruncatedSVD             \nfrom scipy.sparse import hstack                           \n\nmbti_data_cleaned = pd.read_csv('/kaggle/input/mbti-preprocessed/mbti_traditional_new.csv')\n\n# remove NaN texts (TF-IDF cannot handle np.nan)\nmbti_data_cleaned['posts'] = mbti_data_cleaned['posts'].fillna('')  \n\nprint(mbti_data_cleaned['type'].value_counts())\nprint(mbti_data_cleaned['type'].value_counts(normalize=True))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:32:32.116189Z","iopub.execute_input":"2025-11-22T11:32:32.116715Z","iopub.status.idle":"2025-11-22T11:32:32.519756Z","shell.execute_reply.started":"2025-11-22T11:32:32.116691Z","shell.execute_reply":"2025-11-22T11:32:32.519136Z"}},"outputs":[{"name":"stdout","text":"type\nIntrovert    6676\nExtrovert    1999\nName: count, dtype: int64\ntype\nIntrovert    0.769568\nExtrovert    0.230432\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Tokenize\nprint(\"Tokenizing...\")\nmbti_data_cleaned['tokens'] = mbti_data_cleaned['posts'].apply(lambda x: word_tokenize(str(x)))\n\n# Encode Extrovert = 0, Introvert = 1\nprint(\"Encoding...\")\nle = LabelEncoder()\ny = le.fit_transform(mbti_data_cleaned['type'])\n\nX = mbti_data_cleaned[['posts', 'tokens']]  \n\n# Split Data 80/20\nprint(\"Splitting...\")\nX_train, X_test, y_train, y_test = train_test_split(   \n    X, \n    y, \n    test_size=0.2, \n    random_state=42, \n    stratify=y\n)\n\n\nX_train_text = X_train['posts'].tolist()  \nX_test_text = X_test['posts'].tolist()    \nX_train_tokens = X_train['tokens'].tolist()  \nX_test_tokens = X_test['tokens'].tolist()    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:32:54.247820Z","iopub.execute_input":"2025-11-22T11:32:54.248089Z","iopub.status.idle":"2025-11-22T11:33:09.728890Z","shell.execute_reply.started":"2025-11-22T11:32:54.248068Z","shell.execute_reply":"2025-11-22T11:33:09.728201Z"}},"outputs":[{"name":"stdout","text":"Tokenizing...\nEncoding...\nSplitting...\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Train FastText on training data (unsupervised)\nprint(\"Training FastText Model...\")\nfasttext_model = FastText(                 #use 300-dim FastText\n    sentences=X_train_tokens, \n    vector_size=300,                       \n    window=5, \n    min_count=2, \n    sg=1\n)\n\ndef get_w2v_vectors(data, model, vector_size=300):     \n    vectors = []\n    for sentence in data:\n        sentence_vec = np.zeros(vector_size)\n        count = 0\n        for word in sentence:\n            if word in model.wv.key_to_index:\n                sentence_vec += model.wv[word]\n                count += 1\n        if count != 0:\n            sentence_vec /= count\n        vectors.append(sentence_vec)\n    return np.array(vectors)\n\nprint(\"Vectorizing Data with FastText...\")\nX_train_fasttext = get_w2v_vectors(X_train_tokens, fasttext_model, vector_size=300)  #HERE\nX_test_fasttext = get_w2v_vectors(X_test_tokens, fasttext_model, vector_size=300)    #HERE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:33:49.263812Z","iopub.execute_input":"2025-11-22T11:33:49.264437Z","iopub.status.idle":"2025-11-22T11:37:53.852937Z","shell.execute_reply.started":"2025-11-22T11:33:49.264410Z","shell.execute_reply":"2025-11-22T11:37:53.852263Z"}},"outputs":[{"name":"stdout","text":"Training FastText Model...\nVectorizing Data with FastText...\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#TF-IDF word-level (1–2 grams)\nprint(\"Building TF-IDF (word-level)...\")\ntfidf_word = TfidfVectorizer(                     \n    ngram_range=(1, 2),\n    max_features=20000\n)\nX_train_tfidf_word = tfidf_word.fit_transform(X_train_text)   \nX_test_tfidf_word = tfidf_word.transform(X_test_text)         \n\n#TF-IDF char-level (3–5 grams)\nprint(\"Building TF-IDF (char-level)...\")\ntfidf_char = TfidfVectorizer(                     \n    analyzer='char',\n    ngram_range=(3, 5),\n    max_features=20000\n)\nX_train_tfidf_char = tfidf_char.fit_transform(X_train_text)   \nX_test_tfidf_char = tfidf_char.transform(X_test_text)        \n\n#Combine word + char\nprint(\"Combining word & char TF-IDF...\")\nX_train_tfidf = hstack([X_train_tfidf_word, X_train_tfidf_char])  \nX_test_tfidf = hstack([X_test_tfidf_word, X_test_tfidf_char])     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:38:07.665166Z","iopub.execute_input":"2025-11-22T11:38:07.665934Z","iopub.status.idle":"2025-11-22T11:39:16.798267Z","shell.execute_reply.started":"2025-11-22T11:38:07.665907Z","shell.execute_reply":"2025-11-22T11:39:16.797607Z"}},"outputs":[{"name":"stdout","text":"Building TF-IDF (word-level)...\nBuilding TF-IDF (char-level)...\nCombining word & char TF-IDF...\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#Dimensionality reduction with TruncatedSVD (LSA)\nprint(\"Applying TruncatedSVD on TF-IDF...\")\nsvd = TruncatedSVD(n_components=300, random_state=42)        \nX_train_tfidf_svd = svd.fit_transform(X_train_tfidf)         \nX_test_tfidf_svd = svd.transform(X_test_tfidf)               \n\n#Simple extra features – text length stats\ndef length_features(token_list):                             \n    n_words = len(token_list)\n    if n_words == 0:\n        return [0.0, 0.0, 0.0]\n    avg_len = np.mean([len(w) for w in token_list])\n    unique_ratio = len(set(token_list)) / n_words\n    return [n_words, avg_len, unique_ratio]\n\nprint(\"Computing length-based features...\")\nX_train_len_feats = np.array([length_features(toks) for toks in X_train_tokens])  \nX_test_len_feats = np.array([length_features(toks) for toks in X_test_tokens])    \n\n#feature fusion\nprint(\"Fusing TF-IDF(SVD) + FastText + length features...\")\nX_train_final = np.hstack([X_train_tfidf_svd, X_train_fasttext, X_train_len_feats])  \nX_test_final = np.hstack([X_test_tfidf_svd, X_test_fasttext, X_test_len_feats])      \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:39:25.539640Z","iopub.execute_input":"2025-11-22T11:39:25.539914Z","iopub.status.idle":"2025-11-22T11:41:34.001706Z","shell.execute_reply.started":"2025-11-22T11:39:25.539894Z","shell.execute_reply":"2025-11-22T11:41:34.001010Z"}},"outputs":[{"name":"stdout","text":"Applying TruncatedSVD on TF-IDF...\nComputing length-based features...\nFusing TF-IDF(SVD) + FastText + length features...\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#Oversample minority class (extrovert)\nprint(\"Oversampling minority class...\")\nros = RandomOverSampler(random_state=42)                        \nX_train_res, y_train_res = ros.fit_resample(X_train_final, y_train) \nprint(f\"New train class distribution: {np.bincount(y_train_res)}\")   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:41:46.108828Z","iopub.execute_input":"2025-11-22T11:41:46.109368Z","iopub.status.idle":"2025-11-22T11:41:46.154095Z","shell.execute_reply.started":"2025-11-22T11:41:46.109344Z","shell.execute_reply":"2025-11-22T11:41:46.153345Z"}},"outputs":[{"name":"stdout","text":"Oversampling minority class...\nNew train class distribution: [5341 5341]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Define LR and RF\nmodels = {\n    'Logistic Regression': LogisticRegression(\n        max_iter=1000, \n        class_weight='balanced',         \n        n_jobs=-1\n    ),\n    'Random Forest': RandomForestClassifier(\n        class_weight='balanced',\n        random_state=42,\n        n_estimators=300,                \n        n_jobs=-1\n    )\n}\n\nresults = {'Model': [], 'Train Accuracy': [], 'Test Accuracy': []}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:41:50.074444Z","iopub.execute_input":"2025-11-22T11:41:50.075043Z","iopub.status.idle":"2025-11-22T11:41:50.079074Z","shell.execute_reply.started":"2025-11-22T11:41:50.075020Z","shell.execute_reply":"2025-11-22T11:41:50.078461Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(\"Training Classifiers...\")\nfor model_name, model in models.items():\n    model.fit(X_train_res, y_train_res)                       \n    train_acc = model.score(X_train_res, y_train_res)\n    test_acc = model.score(X_test_final, y_test)\n\n    results['Model'].append(model_name + \" (TFIDF+FT)\")\n    results['Train Accuracy'].append(train_acc)\n    results['Test Accuracy'].append(test_acc)\n    print(f\"{model_name}: Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n\n    # F1, confusion matrix\n    y_pred = model.predict(X_test_final)\n    print(f\"\\nClassification Report for {model_name}:\\n\")\n    print(classification_report(y_test, y_pred, target_names=le.classes_))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n    print(\"-\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:41:56.180312Z","iopub.execute_input":"2025-11-22T11:41:56.180581Z","iopub.status.idle":"2025-11-22T11:42:35.358145Z","shell.execute_reply.started":"2025-11-22T11:41:56.180542Z","shell.execute_reply":"2025-11-22T11:42:35.357245Z"}},"outputs":[{"name":"stdout","text":"Training Classifiers...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n\nIncrease the number of iterations to improve the convergence (max_iter=1000).\nYou might also want to scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Logistic Regression: Train Acc: 0.7738, Test Acc: 0.7499\n\nClassification Report for Logistic Regression:\n\n              precision    recall  f1-score   support\n\n   Extrovert       0.47      0.64      0.54       400\n   Introvert       0.88      0.78      0.83      1335\n\n    accuracy                           0.75      1735\n   macro avg       0.67      0.71      0.68      1735\nweighted avg       0.78      0.75      0.76      1735\n\nConfusion Matrix:\n [[ 255  145]\n [ 289 1046]]\n------------------------------------------------------------\nRandom Forest: Train Acc: 1.0000, Test Acc: 0.7729\n\nClassification Report for Random Forest:\n\n              precision    recall  f1-score   support\n\n   Extrovert       0.53      0.12      0.20       400\n   Introvert       0.79      0.97      0.87      1335\n\n    accuracy                           0.77      1735\n   macro avg       0.66      0.55      0.54      1735\nweighted avg       0.73      0.77      0.71      1735\n\nConfusion Matrix:\n [[  50  350]\n [  44 1291]]\n------------------------------------------------------------\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import numpy as np\nfrom scipy.sparse import hstack as sparse_hstack  \n\ndef predict_personality(text):\n   \n    text_clean = text.lower()\n    tfidf_w = tfidf_word.transform([text_clean])\n    tfidf_c = tfidf_char.transform([text_clean])\n    tfidf_combo = sparse_hstack([tfidf_w, tfidf_c])\n    svd_vec = svd.transform(tfidf_combo)\n    tokens = text_clean.split()\n    ft_vec = np.zeros(300)\n    count = 0\n    for w in tokens:\n        if w in fasttext_model.wv.key_to_index:\n            ft_vec += fasttext_model.wv[w]\n            count += 1\n    if count > 0:\n        ft_vec /= count\n    ft_vec = ft_vec.reshape(1, -1)\n    n_words = len(tokens)\n    avg_len = np.mean([len(w) for w in tokens]) if n_words > 0 else 0\n    uniq = len(set(tokens))/n_words if n_words > 0 else 0\n    length_feats = np.array([n_words, avg_len, uniq]).reshape(1, -1)\n    final_vec = np.hstack([svd_vec, ft_vec, length_feats])\n\n    # Use trained LR or RF\n    logreg_model = models[\"Logistic Regression\"]\n    pred = logreg_model.predict(final_vec)\n    return le.inverse_transform(pred)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:51:23.493663Z","iopub.execute_input":"2025-11-22T11:51:23.494216Z","iopub.status.idle":"2025-11-22T11:51:23.500759Z","shell.execute_reply.started":"2025-11-22T11:51:23.494193Z","shell.execute_reply":"2025-11-22T11:51:23.500044Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# textbook extrovert vs \"Reddit-style\" extrovert (casual, opinionated)\ntextbook_extrovert = \"I feel energized when i am around people.\"\nreddit_extrovert = \"Lmao that is hilarious! I literally shouted at my screen. We should totally do a meetup for this sub, it would be chaotic but fun.\"\n\nprint(f\"Textbook Extrovert: {predict_personality(textbook_extrovert)}\")\nprint(f\"Reddit Extrovert:   {predict_personality(reddit_extrovert)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:56:07.756329Z","iopub.execute_input":"2025-11-22T11:56:07.756666Z","iopub.status.idle":"2025-11-22T11:56:07.830138Z","shell.execute_reply.started":"2025-11-22T11:56:07.756640Z","shell.execute_reply":"2025-11-22T11:56:07.829241Z"}},"outputs":[{"name":"stdout","text":"Textbook Extrovert: Introvert\nReddit Extrovert:   Extrovert\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# textbook introvert vs \"Reddit-style\" introvert (casual, opinionated)\ntextbook_introvert = \"I recharge my energy by spending time alone. Social interactions often feel draining to me, and I prefer deep, one-on-one conversations over large groups.\"\nreddit_introvert = \"Ugh, honestly I just want to stay in my room and play video games all weekend. People are so exhausting lol. Does anyone else feel like hiding when the doorbell rings?\"\n\nprint(f\"Textbook Introvert: {predict_personality(textbook_introvert)}\")\nprint(f\"Reddit Introvert:   {predict_personality(reddit_introvert)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T11:53:11.436496Z","iopub.execute_input":"2025-11-22T11:53:11.437095Z","iopub.status.idle":"2025-11-22T11:53:11.509037Z","shell.execute_reply.started":"2025-11-22T11:53:11.437071Z","shell.execute_reply":"2025-11-22T11:53:11.508380Z"}},"outputs":[{"name":"stdout","text":"Textbook Introvert: Introvert\nReddit Introvert:   Introvert\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"***Save model***","metadata":{}},{"cell_type":"code","source":"import joblib\nimport os\n\nsave_dir = \"/kaggle/working/RF\"\nos.makedirs(save_dir, exist_ok=True)\nprint(\"Folder created at:\", save_dir)\nmodels[\"Random Forest\"] #set LR or RF\nrf_model = models[\"Random Forest\"]  \njoblib.dump(rf_model, f\"{save_dir}/random_forest_model.pkl\")\njoblib.dump(tfidf_word, f\"{save_dir}/tfidf_word.pkl\")\njoblib.dump(tfidf_char, f\"{save_dir}/tfidf_char.pkl\")\njoblib.dump(svd, f\"{save_dir}/svd.pkl\")\njoblib.dump(le,    f\"{save_dir}/label_encoder.pkl\")\nfasttext_model.save(f\"{save_dir}/fasttext.model\")\nprint(\"saved to /kaggle/working/RF/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T12:09:04.278469Z","iopub.execute_input":"2025-11-22T12:09:04.278826Z","iopub.status.idle":"2025-11-22T12:09:06.823765Z","shell.execute_reply.started":"2025-11-22T12:09:04.278802Z","shell.execute_reply":"2025-11-22T12:09:06.822875Z"}},"outputs":[{"name":"stdout","text":"Folder created at: /kaggle/working/RF\nsaved to /kaggle/working/RF/\n","output_type":"stream"}],"execution_count":32}]}